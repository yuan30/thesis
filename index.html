<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <title>Real-timeOne-stageRegressionPoseReconstructionSystem</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<link rel="stylesheet" type="text/css" href="css/bootstrap.min.lp.css">
	<link rel="stylesheet" type="text/css" href="css/landing-page.css">
	<link rel="stylesheet" type="text/css" href="font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic">
	<link rel="stylesheet" type="text/css" href="css/styleTest.css">
</head>

<body>
	<!----------------------------------- Dividing line----------------------------------------------------->
	
	<!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top topnav" role="navigation">
        <div class="container topnav">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

                <a class="navbar-brand topnav" href="https://myweb.ntut.edu.tw/~tjhsieh/">
                ♪ 國立臺北科技大學 ♪ 資訊工程系 ♪ 計算機圖學實驗室 ♪</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#top">回頂端</a>
                    </li>
					<li>
                        <a href="#demo1">摘要</a>
                    </li>
					<li>
                        <a href="#demo2">引用文獻</a>
                    </li>
                    <li>
                        <a href="#demo3">示範</a>
                    </li>
					
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>


    <!-- Header -->
    <a name="top"></a>
    <div class="intro-header">
        <div class="container" style="height:350px;">

            <div class="row">
                <div class="col-lg-12" style="height:300px;">
                    <div class="intro-message" style="position: relative;padding-top: 0%;padding-bottom: 70%;">
                        <h1>即時多鏡頭卷積神經網路<br>動作捕捉系統</h1>
                        <h2>Real-Time Multiple Cameras Convolutional Neural Network<br>Motion Capture System</h2>
                        
                    </div>
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.intro-header -->

    <!-- Page Content -->
	<a  name="demo1"></a>
	<div class="content-section-a">

        <div class="container">
            <div class="row">
                <div class="col-lg-5 col-sm-6">
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
					<h2 class="section-heading">
                        摘要
                        <img src="img/hu.svg" alt="" width="100">
                    </h2>
                    
					<p class="lead">本研究開發一套基於直播且容易使用的動作捕捉系統。系統內部採用卷積神經網路模型做姿態的預測，並即時的輸出人體追蹤的結果。
                        對於現在這個網路發達的世界，只要擁有連網設備，如電腦、手機，就能從內建鏡頭透過直播的方式來和其他人互動。
                        而在動作捕捉技術相對成熟的這個時候，相關產業也都受惠於只需要用簡易的設備就能捕捉動作。然而現行最準確的方案，依然是需要穿上具有光學標記點的緊身衣服。
                        但是會有標記點脫落要重黏，及需要穿脫衣物的不便之處。故本論文旨在透過兩支一般的網路攝影機，進行無標記點的姿態偵測。最後利用 Unity 實現這一套可供虛擬主播實況的系統。</p>
                </div>
                <div class="col-lg-7 col-sm-6">
					<br><br><br>
                    <img style="max-width: 125%;" class="img-responsive" src="img/software_architecture.svg" alt="">
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.content-section-a -->

    <a  name="demo2"></a>	
	<div class="content-section-a">

        <div class="container">
            <div class="row">
                <div class="col-lg-5 col-sm-6">
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">引用文獻</h2>
					<p class="lead">
                        Bazarevsky等人提出的 BlazePose 中探討了從影片或影像中姿態估計的挑戰，這在各個領域具有重要的應用。
                        傳統的方法是為每個關節產生熱度圖，但這種方法的計算成本高，不適合在移動手機上進行實時推斷。
                        他們提出了一種基於回歸的方法，使用編碼器-解碼器網絡架構來預測所有關節的熱度圖，然後使用另一個編碼器直接回歸到所有關節的坐標。
                        他們的方法輕量化，可以在推斷過程中不使用熱度圖分支在移動手機上運行，同時仍然可以實現高品質的預測。
                    </p>
                </div>
                <div class="col-lg-5 col-lg-offset-2 col-sm-6 text-center">
					<br><br><br>
                    <!-- Fig 3.6 -->
                    <img class="img-responsive" src="img/mediapipe_2d_pose_offical.png" alt="">
                    <a href="#blazepose">[1]</a>
                    
                </div>
            </div>

            <br>
            <a name="blazepose" href="https://arxiv.org/pdf/2006.10204.pdf">[1] V. Bazarevsky, I. Grishchenko, K. Raveendran, T. Zhu, F. Zhang, and M. Grundmann, “Blazepose: On-device real-time body pose tracking,” in CVPR Workshop on Computer Vision for Augmented and Virtual Reality, Seattle, WA,, June 2020</a>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.content-section-a -->
	
	<a name="demo3"></a>
	<div class="content-section-a">

        <div class="container">
            <div class="row">
                <div class="col-lg-5 col-sm-6">
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
					<h2 class="section-heading">簡介影片</h2>
					<p class="lead">本研究介紹影片，說明本研究目標，以及實驗結果。</p>
                </div>
                <div class="col-lg-5 col-lg-offset-2 col-sm-6">
					<br><br><br>
                    <div class="embed-responsive embed-responsive-16by9">
                        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/OW4ggkb8TWg" allowfullscreen></iframe>
                    </div>
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.content-section-a -->
	

	
    <!-- Footer -->
    <footer>
        <div class="container">
			<div class="row">
                <div class="col-lg-12">
                    <hr>
                    <p></p>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <p class="copyright text-muted small"><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="創用 CC 授權條款" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/InteractiveResource" property="dct:title" rel="dct:type"></span>
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                    <p class="copyright text-muted small">
			論文題目，

            由<a xmlns:cc="http://creativecommons.org/ns#" href="http://www.cc.ntut.edu.tw/~tjhsieh/" property="cc:attributionName" rel="cc:attributionURL">國立臺北科技大學資訊工程系計算機圖學實驗室</a>製作，
			以<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">創用CC 姓名標示-非商業性-相同方式分享 4.0 國際 授權條款</a>釋出。
			姓名標示-非商業性-相同方式分享 CC BY-NC-SA
			本授權條款允許使用者對本著作進行重混、調整，以及依原著作建立新著作，但僅限於非商業目的之使用。唯使用者就其新創著作，必須按照表彰
			原作：國立臺北科技大學資訊工程系計算機圖學實驗室，並且將產出之新創著作採用相同的授權條款釋出。</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="lib/jquery-2.1.3.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="lib/bootstrap.min.js"></script>

	
	
	
	
	
</body>
</html>